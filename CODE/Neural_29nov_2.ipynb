{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 3.72 GiB for an array with shape (1926, 259296) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32md:\\IML ASSIGNMENT 2\\CODE\\Neural_29nov_2.ipynb Cell 1\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/IML%20ASSIGNMENT%202/CODE/Neural_29nov_2.ipynb#W0sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# Variance filter to remove low-variance features\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/IML%20ASSIGNMENT%202/CODE/Neural_29nov_2.ipynb#W0sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m variance_filter \u001b[39m=\u001b[39m VarianceThreshold(threshold\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/IML%20ASSIGNMENT%202/CODE/Neural_29nov_2.ipynb#W0sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m combined_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(variance_filter\u001b[39m.\u001b[39;49mfit_transform(combined_data), columns\u001b[39m=\u001b[39mcombined_data\u001b[39m.\u001b[39mcolumns[variance_filter\u001b[39m.\u001b[39mget_support()])\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/IML%20ASSIGNMENT%202/CODE/Neural_29nov_2.ipynb#W0sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m# Split combined_data back into train and test\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/IML%20ASSIGNMENT%202/CODE/Neural_29nov_2.ipynb#W0sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m X \u001b[39m=\u001b[39m combined_data[:\u001b[39mlen\u001b[39m(X)]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 157\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    158\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    159\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    160\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[0;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    162\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    163\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:916\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    914\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    915\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 916\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[0;32m    917\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    918\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    919\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\feature_selection\\_variance_threshold.py:99\u001b[0m, in \u001b[0;36mVarianceThreshold.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[39m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     81\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     82\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Learn empirical variances from X.\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \n\u001b[0;32m     84\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[39m        Returns the instance itself.\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 99\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    100\u001b[0m         X,\n\u001b[0;32m    101\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    102\u001b[0m         dtype\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mfloat64,\n\u001b[0;32m    103\u001b[0m         force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    104\u001b[0m     )\n\u001b[0;32m    106\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(X, \u001b[39m\"\u001b[39m\u001b[39mtoarray\u001b[39m\u001b[39m\"\u001b[39m):  \u001b[39m# sparse matrix\u001b[39;00m\n\u001b[0;32m    107\u001b[0m         _, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvariances_ \u001b[39m=\u001b[39m mean_variance_axis(X, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:605\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    603\u001b[0m         out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    604\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 605\u001b[0m     out \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[0;32m    606\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    607\u001b[0m     out \u001b[39m=\u001b[39m _check_y(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:836\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    831\u001b[0m \u001b[39mif\u001b[39;00m pandas_requires_conversion:\n\u001b[0;32m    832\u001b[0m     \u001b[39m# pandas dataframe requires conversion earlier to handle extension dtypes with\u001b[39;00m\n\u001b[0;32m    833\u001b[0m     \u001b[39m# nans\u001b[39;00m\n\u001b[0;32m    834\u001b[0m     \u001b[39m# Use the original dtype for conversion if dtype is None\u001b[39;00m\n\u001b[0;32m    835\u001b[0m     new_dtype \u001b[39m=\u001b[39m dtype_orig \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m dtype\n\u001b[1;32m--> 836\u001b[0m     array \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39;49mastype(new_dtype)\n\u001b[0;32m    837\u001b[0m     \u001b[39m# Since we converted here, we do not need to convert again later\u001b[39;00m\n\u001b[0;32m    838\u001b[0m     dtype \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\generic.py:6534\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6530\u001b[0m     results \u001b[39m=\u001b[39m [ser\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy) \u001b[39mfor\u001b[39;00m _, ser \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems()]\n\u001b[0;32m   6532\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   6533\u001b[0m     \u001b[39m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6534\u001b[0m     new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mastype(dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   6535\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[39m=\u001b[39mnew_data\u001b[39m.\u001b[39maxes)\n\u001b[0;32m   6536\u001b[0m     \u001b[39mreturn\u001b[39;00m res\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mastype\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\internals\\managers.py:414\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    411\u001b[0m \u001b[39melif\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    412\u001b[0m     copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m--> 414\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply(\n\u001b[0;32m    415\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mastype\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    416\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    417\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    418\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    419\u001b[0m     using_cow\u001b[39m=\u001b[39;49musing_copy_on_write(),\n\u001b[0;32m    420\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\internals\\managers.py:354\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    352\u001b[0m         applied \u001b[39m=\u001b[39m b\u001b[39m.\u001b[39mapply(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 354\u001b[0m         applied \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(b, f)(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    355\u001b[0m     result_blocks \u001b[39m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    357\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mfrom_blocks(result_blocks, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\internals\\blocks.py:616\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors, using_cow)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    597\u001b[0m \u001b[39mCoerce to the new dtype.\u001b[39;00m\n\u001b[0;32m    598\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[39mBlock\u001b[39;00m\n\u001b[0;32m    613\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    614\u001b[0m values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues\n\u001b[1;32m--> 616\u001b[0m new_values \u001b[39m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m    618\u001b[0m new_values \u001b[39m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    620\u001b[0m refs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\dtypes\\astype.py:238\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    235\u001b[0m     dtype \u001b[39m=\u001b[39m dtype\u001b[39m.\u001b[39mnumpy_dtype\n\u001b[0;32m    237\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 238\u001b[0m     new_values \u001b[39m=\u001b[39m astype_array(values, dtype, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[0;32m    239\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m):\n\u001b[0;32m    240\u001b[0m     \u001b[39m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[39m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    242\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\dtypes\\astype.py:183\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    180\u001b[0m     values \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m    182\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 183\u001b[0m     values \u001b[39m=\u001b[39m _astype_nansafe(values, dtype, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[0;32m    185\u001b[0m \u001b[39m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, np\u001b[39m.\u001b[39mdtype) \u001b[39mand\u001b[39;00m \u001b[39missubclass\u001b[39m(values\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, \u001b[39mstr\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\dtypes\\astype.py:134\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[0;32m    132\u001b[0m \u001b[39mif\u001b[39;00m copy \u001b[39mor\u001b[39;00m arr\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m \u001b[39mobject\u001b[39m \u001b[39mor\u001b[39;00m dtype \u001b[39m==\u001b[39m \u001b[39mobject\u001b[39m:\n\u001b[0;32m    133\u001b[0m     \u001b[39m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m     \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39;49mastype(dtype, copy\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    136\u001b[0m \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 3.72 GiB for an array with shape (1926, 259296) and data type float64"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures, RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.impute import SimpleImputer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adamax\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('price_doc', axis=1)\n",
    "y = df['price_doc']\n",
    "\n",
    "# Combine train and test for consistent preprocessing\n",
    "combined_data = pd.concat([X, df_test], axis=0)\n",
    "\n",
    "# One-hot encoding for categorical variables\n",
    "object_cols = combined_data.select_dtypes(include=['object']).columns\n",
    "combined_data = pd.get_dummies(combined_data, columns=object_cols, drop_first=True)\n",
    "\n",
    "# Variance filter to remove low-variance features\n",
    "variance_filter = VarianceThreshold(threshold=0.01)\n",
    "combined_data = pd.DataFrame(variance_filter.fit_transform(combined_data), columns=combined_data.columns[variance_filter.get_support()])\n",
    "\n",
    "# Split combined_data back into train and test\n",
    "X = combined_data[:len(X)]\n",
    "df_test = combined_data[len(X):]\n",
    "\n",
    "# Feature scaling\n",
    "scaler = RobustScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "df_test = scaler.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensionality reduction with PCA\n",
    "pca = PCA(n_components=15)\n",
    "X = pca.fit_transform(X)\n",
    "df_test = pca.transform(df_test)\n",
    "\n",
    "# Polynomial features\n",
    "poly = PolynomialFeatures(degree=3)\n",
    "X = poly.fit_transform(X)\n",
    "df_test = poly.transform(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "n_features = X.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Dense(150, input_dim=n_features, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(80, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(35, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(optimizer=Adamax(learning_rate=0.01), loss='mean_squared_error')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)\n",
    "model.fit(X, y, epochs=100, batch_size=256, callbacks=[early_stopping])\n",
    "\n",
    "# Prediction\n",
    "y_pred = model.predict(df_test)\n",
    "\n",
    "# Save predictions to a CSV file\n",
    "result_df = pd.DataFrame({'row ID': range(1, len(y_pred) + 1), 'price_doc': y_pred.flatten()})\n",
    "result_df.to_csv('neural_29nov_3_improved.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
