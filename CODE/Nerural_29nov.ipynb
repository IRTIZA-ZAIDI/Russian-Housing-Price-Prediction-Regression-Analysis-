{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Irtiza\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.99 GiB for an array with shape (2214, 181507) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32md:\\IML ASSIGNMENT 2\\CODE\\Nerural_29nov.ipynb Cell 1\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/IML%20ASSIGNMENT%202/CODE/Nerural_29nov.ipynb#W0sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# Feature scaling\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/IML%20ASSIGNMENT%202/CODE/Nerural_29nov.ipynb#W0sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m scaler \u001b[39m=\u001b[39m RobustScaler()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/IML%20ASSIGNMENT%202/CODE/Nerural_29nov.ipynb#W0sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m X \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39;49mfit_transform(X)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/IML%20ASSIGNMENT%202/CODE/Nerural_29nov.ipynb#W0sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m df_test \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39mtransform(df_test)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/IML%20ASSIGNMENT%202/CODE/Nerural_29nov.ipynb#W0sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# Dimensionality reduction with PCA\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 157\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    158\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    159\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    160\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[0;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    162\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    163\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:916\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    914\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    915\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 916\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[0;32m    917\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    918\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    919\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\preprocessing\\_data.py:1533\u001b[0m, in \u001b[0;36mRobustScaler.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Compute the median and quantiles to be used for scaling.\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \n\u001b[0;32m   1517\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1529\u001b[0m \u001b[39m    Fitted scaler.\u001b[39;00m\n\u001b[0;32m   1530\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[39m# at fit, convert sparse matrices to csc for optimized computation of\u001b[39;00m\n\u001b[0;32m   1532\u001b[0m \u001b[39m# the quantiles\u001b[39;00m\n\u001b[1;32m-> 1533\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m   1534\u001b[0m     X,\n\u001b[0;32m   1535\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1536\u001b[0m     dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES,\n\u001b[0;32m   1537\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1538\u001b[0m )\n\u001b[0;32m   1540\u001b[0m q_min, q_max \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquantile_range\n\u001b[0;32m   1541\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m0\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m q_min \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m q_max \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m100\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:605\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    603\u001b[0m         out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    604\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 605\u001b[0m     out \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[0;32m    606\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    607\u001b[0m     out \u001b[39m=\u001b[39m _check_y(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:915\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    913\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    914\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 915\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype, xp\u001b[39m=\u001b[39;49mxp)\n\u001b[0;32m    916\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    917\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    918\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    919\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\_array_api.py:380\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    378\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39marray(array, order\u001b[39m=\u001b[39morder, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m    379\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 380\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    382\u001b[0m \u001b[39m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[39m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\generic.py:2083\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2082\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype: npt\u001b[39m.\u001b[39mDTypeLike \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m-> 2083\u001b[0m     values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_values\n\u001b[0;32m   2084\u001b[0m     arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(values, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m   2085\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   2086\u001b[0m         astype_is_view(values\u001b[39m.\u001b[39mdtype, arr\u001b[39m.\u001b[39mdtype)\n\u001b[0;32m   2087\u001b[0m         \u001b[39mand\u001b[39;00m using_copy_on_write()\n\u001b[0;32m   2088\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mgr\u001b[39m.\u001b[39mis_single_block\n\u001b[0;32m   2089\u001b[0m     ):\n\u001b[0;32m   2090\u001b[0m         \u001b[39m# Check if both conversions can be done without a copy\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\frame.py:1046\u001b[0m, in \u001b[0;36mDataFrame._values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1044\u001b[0m blocks \u001b[39m=\u001b[39m mgr\u001b[39m.\u001b[39mblocks\n\u001b[0;32m   1045\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(blocks) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m-> 1046\u001b[0m     \u001b[39mreturn\u001b[39;00m ensure_wrapped_if_datetimelike(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalues)\n\u001b[0;32m   1048\u001b[0m arr \u001b[39m=\u001b[39m blocks[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mvalues\n\u001b[0;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m arr\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1050\u001b[0m     \u001b[39m# non-2D ExtensionArray\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\frame.py:12281\u001b[0m, in \u001b[0;36mDataFrame.values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m  12207\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[0;32m  12208\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvalues\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[0;32m  12209\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m  12210\u001b[0m \u001b[39m    Return a Numpy representation of the DataFrame.\u001b[39;00m\n\u001b[0;32m  12211\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  12279\u001b[0m \u001b[39m           ['monkey', nan, None]], dtype=object)\u001b[39;00m\n\u001b[0;32m  12280\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m> 12281\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mas_array()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\internals\\managers.py:1656\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1654\u001b[0m         arr\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mwriteable \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1656\u001b[0m     arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interleave(dtype\u001b[39m=\u001b[39;49mdtype, na_value\u001b[39m=\u001b[39;49mna_value)\n\u001b[0;32m   1657\u001b[0m     \u001b[39m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[0;32m   1658\u001b[0m     \u001b[39m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[0;32m   1660\u001b[0m \u001b[39mif\u001b[39;00m na_value \u001b[39mis\u001b[39;00m lib\u001b[39m.\u001b[39mno_default:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\internals\\managers.py:1689\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[1;34m(self, dtype, na_value)\u001b[0m\n\u001b[0;32m   1686\u001b[0m \u001b[39m# error: Argument 1 to \"ensure_np_dtype\" has incompatible type\u001b[39;00m\n\u001b[0;32m   1687\u001b[0m \u001b[39m# \"Optional[dtype[Any]]\"; expected \"Union[dtype[Any], ExtensionDtype]\"\u001b[39;00m\n\u001b[0;32m   1688\u001b[0m dtype \u001b[39m=\u001b[39m ensure_np_dtype(dtype)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m-> 1689\u001b[0m result \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mempty(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshape, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m   1691\u001b[0m itemmask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n\u001b[0;32m   1693\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mdtype(\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m na_value \u001b[39mis\u001b[39;00m lib\u001b[39m.\u001b[39mno_default:\n\u001b[0;32m   1694\u001b[0m     \u001b[39m# much more performant than using to_numpy below\u001b[39;00m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 2.99 GiB for an array with shape (2214, 181507) and data type float64"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, PolynomialFeatures, RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adamax\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "\n",
    "df1_encoded = pd.get_dummies(df)\n",
    "df2_encoded = pd.get_dummies(df_test)\n",
    "\n",
    "X = df1_encoded.drop(columns=['price_doc'], axis=1)\n",
    "y = df1_encoded['price_doc']\n",
    "\n",
    "# Feature scaling\n",
    "scaler = RobustScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "df_test = scaler.transform(df_test)\n",
    "\n",
    "# Dimensionality reduction with PCA\n",
    "pca = PCA(n_components=15)\n",
    "X = pca.fit_transform(X)\n",
    "df_test = pca.transform(df_test)\n",
    "\n",
    "# Polynomial features\n",
    "poly = PolynomialFeatures(degree=3)\n",
    "X = poly.fit_transform(X)\n",
    "df_test = poly.transform(df_test)\n",
    "\n",
    "# Model\n",
    "n_features = X.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Dense(150, input_dim=n_features, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(80, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(35, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(optimizer=Adamax(learning_rate=0.01), loss='mean_squared_error')\n",
    "\n",
    "# Model training\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)\n",
    "model.fit(X, y, epochs=100, batch_size=256, callbacks=[early_stopping])\n",
    "\n",
    "# Prediction\n",
    "y_pred = model.predict(df_test)\n",
    "\n",
    "# Save predictions to a CSV file\n",
    "result_df = pd.DataFrame({'row ID': range(1, len(y_pred) + 1), 'price_doc': y_pred.flatten()})\n",
    "result_df.to_csv('neural_29nov_4_improved.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
