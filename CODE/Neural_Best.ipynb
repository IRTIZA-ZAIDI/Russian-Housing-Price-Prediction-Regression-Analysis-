{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import csv\n",
    "import statsmodels.api as sm\n",
    "from sklearn.feature_selection import SelectKBest,f_regression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:, df.columns != 'price_doc']\n",
    "y = df[['price_doc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Irtiza\\AppData\\Local\\Temp\\ipykernel_18000\\2848903810.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.drop(columns=object_cols,axis=1,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "object_cols = X.select_dtypes(include=['object']).columns\n",
    "X.drop(columns=object_cols,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label = LabelEncoder()\n",
    "# for col in object_cols:\n",
    "#     X[col] = label.fit_transform(X[col].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178661, 256)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = X.select_dtypes(include=['int64','float64']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Irtiza\\AppData\\Local\\Temp\\ipykernel_18000\\334397748.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[num_cols] = scaler.fit_transform(X[num_cols])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler,RobustScaler\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X[num_cols] = scaler.fit_transform(X[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178661, 256)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=70)\n",
    "X = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# poly = PolynomialFeatures(degree=3)\n",
    "# X = poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178661, 70)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.drop(['row ID'], axis=1)\n",
    "df_test.drop(columns=object_cols,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_test = LabelEncoder()\n",
    "# for col in object_cols:\n",
    "#     df_test[col] = label_test.fit_transform(df_test[col].astype(str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77789, 256)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[num_cols] = scaler.transform(df_test[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pca.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test = poly.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77789, 70)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert all int64 to float32\n",
    "X = X.astype('float32')\n",
    "df_test = df_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Irtiza\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.regularizers import l1, l2\n",
    "from keras.optimizers import RMSprop,Adam,Adamax\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Irtiza\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 344117019644141.31250000\n",
      "Validation score: -0.168586\n",
      "Iteration 2, loss = 142886171861365.81250000\n",
      "Validation score: 0.548819\n",
      "Iteration 3, loss = 99570683109300.04687500\n",
      "Validation score: 0.602607\n",
      "Iteration 4, loss = 93499770410337.59375000\n",
      "Validation score: 0.614128\n",
      "Iteration 5, loss = 91883667586914.46875000\n",
      "Validation score: 0.618612\n",
      "Iteration 6, loss = 91206273422918.56250000\n",
      "Validation score: 0.620477\n",
      "Iteration 7, loss = 90901103222274.67187500\n",
      "Validation score: 0.621448\n",
      "Iteration 8, loss = 90670816446319.95312500\n",
      "Validation score: 0.622290\n",
      "Iteration 9, loss = 90507969852210.32812500\n",
      "Validation score: 0.622660\n",
      "Iteration 10, loss = 90385082044727.20312500\n",
      "Validation score: 0.620730\n",
      "Iteration 11, loss = 90349286493510.40625000\n",
      "Validation score: 0.623339\n",
      "Iteration 12, loss = 90168133528282.35937500\n",
      "Validation score: 0.624020\n",
      "Iteration 13, loss = 90102616734734.29687500\n",
      "Validation score: 0.624187\n",
      "Iteration 14, loss = 90039266643497.12500000\n",
      "Validation score: 0.624407\n",
      "Iteration 15, loss = 89914603290140.98437500\n",
      "Validation score: 0.624252\n",
      "Iteration 16, loss = 89831897676754.42187500\n",
      "Validation score: 0.624475\n",
      "Iteration 17, loss = 89789125070154.56250000\n",
      "Validation score: 0.625281\n",
      "Iteration 18, loss = 89703399673211.32812500\n",
      "Validation score: 0.624849\n",
      "Iteration 19, loss = 89642389803832.03125000\n",
      "Validation score: 0.625367\n",
      "Iteration 20, loss = 89672148960012.10937500\n",
      "Validation score: 0.625416\n",
      "Iteration 21, loss = 89513941679258.85937500\n",
      "Validation score: 0.625811\n",
      "Iteration 22, loss = 89563256014191.25000000\n",
      "Validation score: 0.625844\n",
      "Iteration 23, loss = 89446954812016.45312500\n",
      "Validation score: 0.626042\n",
      "Iteration 24, loss = 89393422567892.48437500\n",
      "Validation score: 0.626187\n",
      "Iteration 25, loss = 89343072885271.51562500\n",
      "Validation score: 0.626421\n",
      "Iteration 26, loss = 89333284169330.34375000\n",
      "Validation score: 0.626316\n",
      "Iteration 27, loss = 89232807826074.68750000\n",
      "Validation score: 0.626478\n",
      "Iteration 28, loss = 89212809378711.84375000\n",
      "Validation score: 0.626794\n",
      "Iteration 29, loss = 89170596749390.23437500\n",
      "Validation score: 0.626971\n",
      "Iteration 30, loss = 89102079697501.14062500\n",
      "Validation score: 0.626746\n",
      "Iteration 31, loss = 89161763903432.84375000\n",
      "Validation score: 0.627407\n",
      "Iteration 32, loss = 89008605855440.26562500\n",
      "Validation score: 0.627608\n",
      "Iteration 33, loss = 89050441991375.81250000\n",
      "Validation score: 0.627313\n",
      "Iteration 34, loss = 88910721151008.34375000\n",
      "Validation score: 0.627847\n",
      "Iteration 35, loss = 88887299740450.68750000\n",
      "Validation score: 0.628285\n",
      "Iteration 36, loss = 88846701943478.95312500\n",
      "Validation score: 0.626059\n",
      "Iteration 37, loss = 88716390802758.39062500\n",
      "Validation score: 0.627768\n",
      "Iteration 38, loss = 88645115177408.46875000\n",
      "Validation score: 0.626684\n",
      "Iteration 39, loss = 88584773592203.35937500\n",
      "Validation score: 0.629199\n",
      "Iteration 40, loss = 88485097632042.32812500\n",
      "Validation score: 0.629445\n",
      "Iteration 41, loss = 88448703150271.53125000\n",
      "Validation score: 0.629818\n",
      "Iteration 42, loss = 88326134805640.96875000\n",
      "Validation score: 0.630068\n",
      "Iteration 43, loss = 88306921471776.98437500\n",
      "Validation score: 0.629483\n",
      "Iteration 44, loss = 88214370973297.76562500\n",
      "Validation score: 0.630629\n",
      "Iteration 45, loss = 88163067422489.89062500\n",
      "Validation score: 0.630647\n",
      "Iteration 46, loss = 88077207197929.14062500\n",
      "Validation score: 0.631222\n",
      "Iteration 47, loss = 87947007906983.93750000\n",
      "Validation score: 0.631561\n",
      "Iteration 48, loss = 87883405044860.79687500\n",
      "Validation score: 0.631730\n",
      "Iteration 49, loss = 87879826797805.37500000\n",
      "Validation score: 0.631944\n",
      "Iteration 50, loss = 87831462923526.26562500\n",
      "Validation score: 0.632154\n",
      "Iteration 51, loss = 87701455875054.68750000\n",
      "Validation score: 0.631908\n",
      "Iteration 52, loss = 87670856076957.54687500\n",
      "Validation score: 0.632908\n",
      "Iteration 53, loss = 87707006559142.67187500\n",
      "Validation score: 0.632346\n",
      "Iteration 54, loss = 87501926898768.62500000\n",
      "Validation score: 0.633073\n",
      "Iteration 55, loss = 87426683361713.95312500\n",
      "Validation score: 0.633311\n",
      "Iteration 56, loss = 87427987848341.12500000\n",
      "Validation score: 0.633514\n",
      "Iteration 57, loss = 87306948578000.04687500\n",
      "Validation score: 0.633581\n",
      "Iteration 58, loss = 87273723657032.95312500\n",
      "Validation score: 0.634161\n",
      "Iteration 59, loss = 87256614135482.32812500\n",
      "Validation score: 0.634148\n",
      "Iteration 60, loss = 87207891673490.51562500\n",
      "Validation score: 0.633924\n",
      "Iteration 61, loss = 87060397420834.35937500\n",
      "Validation score: 0.634545\n",
      "Iteration 62, loss = 86992341721522.71875000\n",
      "Validation score: 0.634669\n",
      "Iteration 63, loss = 86959915171532.03125000\n",
      "Validation score: 0.635064\n",
      "Iteration 64, loss = 86899320269809.81250000\n",
      "Validation score: 0.634261\n",
      "Iteration 65, loss = 86863674718465.37500000\n",
      "Validation score: 0.634711\n",
      "Iteration 66, loss = 86910686426978.09375000\n",
      "Validation score: 0.635523\n",
      "Iteration 67, loss = 86766422224031.75000000\n",
      "Validation score: 0.634904\n",
      "Iteration 68, loss = 86633119425065.98437500\n",
      "Validation score: 0.635574\n",
      "Iteration 69, loss = 86521167135155.10937500\n",
      "Validation score: 0.636145\n",
      "Iteration 70, loss = 86474858667783.15625000\n",
      "Validation score: 0.635718\n",
      "Iteration 71, loss = 86410744677962.42187500\n",
      "Validation score: 0.636134\n",
      "Iteration 72, loss = 86321226776136.53125000\n",
      "Validation score: 0.636800\n",
      "Iteration 73, loss = 86227583766266.67187500\n",
      "Validation score: 0.636503\n",
      "Iteration 74, loss = 86123995703101.93750000\n",
      "Validation score: 0.636924\n",
      "Iteration 75, loss = 86054668850060.23437500\n",
      "Validation score: 0.637128\n",
      "Iteration 76, loss = 85945784467591.06250000\n",
      "Validation score: 0.637351\n",
      "Iteration 77, loss = 85865989354211.60937500\n",
      "Validation score: 0.637732\n",
      "Iteration 78, loss = 85835963896065.90625000\n",
      "Validation score: 0.637143\n",
      "Iteration 79, loss = 85693462918332.93750000\n",
      "Validation score: 0.637637\n",
      "Iteration 80, loss = 85577824695428.48437500\n",
      "Validation score: 0.637944\n",
      "Iteration 81, loss = 85535699014068.28125000\n",
      "Validation score: 0.636673\n",
      "Iteration 82, loss = 85440754174886.10937500\n",
      "Validation score: 0.636869\n",
      "Iteration 83, loss = 85391272864991.28125000\n",
      "Validation score: 0.637920\n",
      "Iteration 84, loss = 85226175946509.64062500\n",
      "Validation score: 0.638218\n",
      "Iteration 85, loss = 85260049731859.39062500\n",
      "Validation score: 0.637262\n",
      "Iteration 86, loss = 85042294117219.60937500\n",
      "Validation score: 0.637770\n",
      "Iteration 87, loss = 84918861857230.81250000\n",
      "Validation score: 0.638677\n",
      "Iteration 88, loss = 84830669655485.81250000\n",
      "Validation score: 0.638956\n",
      "Iteration 89, loss = 84708562116164.01562500\n",
      "Validation score: 0.638356\n",
      "Iteration 90, loss = 84615483645268.28125000\n",
      "Validation score: 0.639366\n",
      "Iteration 91, loss = 84528261217398.43750000\n",
      "Validation score: 0.638503\n",
      "Iteration 92, loss = 84445040063502.01562500\n",
      "Validation score: 0.639049\n",
      "Iteration 93, loss = 84255195235140.04687500\n",
      "Validation score: 0.639052\n",
      "Iteration 94, loss = 84219921085664.32812500\n",
      "Validation score: 0.638915\n",
      "Iteration 95, loss = 84151544686935.60937500\n",
      "Validation score: 0.638856\n",
      "Iteration 96, loss = 84035883858714.60937500\n",
      "Validation score: 0.638629\n",
      "Iteration 97, loss = 83960387745463.73437500\n",
      "Validation score: 0.639181\n",
      "Iteration 98, loss = 83822142368910.70312500\n",
      "Validation score: 0.639501\n",
      "Iteration 99, loss = 83739212700144.87500000\n",
      "Validation score: 0.638618\n",
      "Iteration 100, loss = 83604237495386.25000000\n",
      "Validation score: 0.639042\n",
      "Iteration 101, loss = 83632924898527.65625000\n",
      "Validation score: 0.638410\n",
      "Iteration 102, loss = 83513870169494.87500000\n",
      "Validation score: 0.638982\n",
      "Iteration 103, loss = 83507748172747.26562500\n",
      "Validation score: 0.639206\n",
      "Iteration 104, loss = 83355325211175.76562500\n",
      "Validation score: 0.639424\n",
      "Iteration 105, loss = 83252355345813.71875000\n",
      "Validation score: 0.636723\n",
      "Iteration 106, loss = 83299314871969.79687500\n",
      "Validation score: 0.637211\n",
      "Iteration 107, loss = 83120647547701.90625000\n",
      "Validation score: 0.639321\n",
      "Iteration 108, loss = 83026649534162.00000000\n",
      "Validation score: 0.638906\n",
      "Iteration 109, loss = 82972802341077.01562500\n",
      "Validation score: 0.637610\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# MLPRegressor with dropout and regularization\n",
    "mlp = MLPRegressor(\n",
    "    hidden_layer_sizes=(150, 110, 80, 40,25 ),\n",
    "    max_iter=200,\n",
    "    solver='adam',\n",
    "    verbose=True,\n",
    "    shuffle=True,\n",
    "    batch_size=1300,\n",
    "    early_stopping=True,\n",
    "    alpha=0.0001 \n",
    ")\n",
    "\n",
    "mlp.fit(X,y)\n",
    "\n",
    "# Evaluate on the validation set\n",
    "y_val_pred = mlp.predict(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get the number of input features in X and assign to n_features\n",
    "# n_features = X.shape[1]\n",
    "# # Create a Sequential model\n",
    "# model = Sequential()\n",
    "\n",
    "# # Add the first hidden layer with 10 neurons and specify the input shape\n",
    "# model.add(Dense(128, input_dim=n_features, activation='relu'))\n",
    "\n",
    "# # Add the second hidden layer with 5 neurons\n",
    "# model.add(Dense(100, activation='relu'))\n",
    "\n",
    "# # Add the third hidden layer with 3 neurons\n",
    "# model.add(Dense(64, activation='relu'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer=RMSprop(learning_rate=0.01), loss='mean_squared_error') #change optimizer\n",
    "\n",
    "# # Print the model summary\n",
    "# print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early_stopping = EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)\n",
    "# model.fit(X, y, epochs=100, batch_size=2048, callbacks=[early_stopping])\n",
    "# y_pred = model.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'nerual_29nov_1.csv'\n",
    "with open(filepath, mode='w', newline='') as file: \n",
    "    writer = csv.writer(file)\n",
    "    c=1\n",
    "    writer.writerow(['row ID', 'price_doc'])\n",
    "    for i in y_val_pred:\n",
    "        writer.writerow([c ,i])\n",
    "        c=c+1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
